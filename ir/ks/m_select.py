# -*- coding: utf-8 -*-
"""m_select.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18cYbOrmBXfDElSUkOdKplEEm03DTj1M4

## m_select READ ME
Date Version : 10/01/2024

The m_select project is designed for image analysis, specifically focusing on the detection and comparison of tumor contours in medical images. This code allows users to load two images, typically representing different time points or conditions of the same subject, and perform various operations including contrast enhancement, mask generation, and keypoint selection. The tool enables users to manually select keypoints on the tumor contours, calculate distances between corresponding points, and analyze the radial displacement within defined sectors around the tumor. The results, including matched keypoints and distance metrics, can be saved for further analysis in an Excel format. This project is intended for researchers and medical professionals interested in quantitative analysis of tumor changes over time or in response to treatment.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
import imageio
import pandas as pd
from skimage.filters import threshold_otsu, gaussian
from skimage.morphology import binary_closing, disk, remove_small_objects, label
from scipy.ndimage.measurements import center_of_mass
scale=0.5
def load_images(paths):
    '''
    Reads and resizes all images from the provided file paths list.
    'paths' is a list of file paths to images.
    Each image is resized using the 'resize_image' function with a default scale.
    '''
    # resize to have a full view of the picture
    images = [resize_image(imageio.imread(path), scale=scale) for path in paths]
    return images

def resize_image(image, scale=0.5, width=None, height=None):
    '''
    Resizes the given image based on either scale, width, or height.
    If scale is provided, it will scale the image by that factor (default 0.5).
    If width and height are provided, it will resize the image to those dimensions.
    If only width or height is provided, it will maintain the image aspect ratio.
    Raises a ValueError if neither scale, width, nor height is specified.

    Parameters:
        image (ndarray): The image to be resized.
        scale (float): The scaling factor for the image. Default is 0.5.
        width (int): The desired width of the image (optional).
        height (int): The desired height of the image (optional).

    Returns:
        resized (ndarray): The resized image.
    '''
    # Get original height and width of the image
    (h, w) = image.shape[:2]
    if scale:
        # Resize the image using the provided scale factor
        new_dim = (int(w * scale), int(h * scale))
    elif width and height:
        # Resize to specified width and height
        new_dim = (width, height)
    elif width:
        # Resize based on width, maintaining the aspect ratio
        scale = width / float(w)
        new_dim = (width, int(h * scale))
    elif height:
        # Resize based on height, maintaining the aspect ratio
        scale = height / float(h)
        new_dim = (int(w * scale), height)
    else:
        # Raise an error if no valid resizing parameters are provided
        raise ValueError("You must provide either scale, width, or height.")

    # Resize the image using the calculated dimensions and return it
    resized = cv2.resize(image, new_dim, interpolation=cv2.INTER_AREA)
    return resized

def create_circle_mask(img, radius=500):
    '''
    Creates a circular mask over the input image and applies it to return the masked image.
    This mask is useful for isolating a specific region of interest within the image,
    such as a tumor or other structures that are roughly circular in shape.

    Parameters:
        img (ndarray): The input image to apply the circular mask.
        radius (int): The radius of the circle mask. Default is 500 pixels.

    Returns:
        mask (ndarray): The binary mask with the circular region.
        masked_image (ndarray): The image with the circular mask applied.
    '''
    # Get the height and width of the image
    height, width = img.shape[:2]
    # Create a black mask with the same dimensions as the image
    mask = np.zeros((height, width), dtype=np.uint8)
    # Calculate the center of the image
    center_x, center_y = width // 2, height // 2
    # Draw a white filled circle on the mask
    cv2.circle(mask, (center_x, center_y), radius, 255, -1)
    # Apply the circular mask to the image using bitwise_and operation
    masked_image = cv2.bitwise_and(img, img, mask=mask)
    return mask, masked_image

def enhance_contrast(image, clip_limit=5.0):
    '''
    Enhances the contrast of the input image using CLAHE (Contrast Limited Adaptive Histogram Equalization).
    （Enhancing contrast works by adjusting the grayscale values of an image,
    increasing the difference between light and dark areas.
    This process makes details more visible by stretching or redistributing the pixel intensities.
    For example, in medical images, enhancing contrast helps distinguish subtle differences between tissues,
    making structures like tumors stand out more clearly for further analysis.）

    Parameters:
        image (ndarray): The grayscale image to enhance.
        clip_limit (float): Threshold for contrast limiting. Default is 5.0.

    Returns:
        enhanced_image (ndarray): The contrast-enhanced image.
    '''
    # Create a CLAHE object with specified clip limit and grid size
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(27, 27))
    # Apply CLAHE to the input image and return the enhanced image
    enhanced_image = clahe.apply(image)
    return enhanced_image

def adjust_threshold(image, threshold_scale):
    '''
    Adjusts the threshold of the input image using Otsu's method, scaled by the provided factor.
    It allows for adaptive thresholding, where the threshold level can be scaled to improve the
    distinction between different image regions. By modifying the threshold, it helps in better
    isolating relevant features (e.g., tumors) from noise, facilitating more accurate analysis and processing in subsequent steps.

    Parameters:
        image (ndarray): The input image to threshold (typically grayscale).
        threshold_scale (float): The scaling factor to adjust the Otsu threshold.

    Returns:
        binary_image (ndarray): The binary image after thresholding, where pixel values are 0 or 1.
    '''
    # Compute the Otsu threshold
    otsu_thresh = threshold_otsu(image)
    # Adjust the threshold by multiplying with the scale factor
    adjusted_thresh = otsu_thresh * threshold_scale
    # Apply the threshold and create a binary image (inverted mask)
    binary_image = image < adjusted_thresh  # Invert the binary mask
    return binary_image

def create_largest_contour_mask(image, threshold_scale=1.3):
    '''
    Creates a binary mask for the largest contour in the input image based on a thresholding operation.
    By creating a mask based on this largest contour, we can focus on the region of interest for further analysis,
    avoiding noise or irrelevant areas of the image.

    Parameters:
        image (ndarray): The input grayscale image.
        threshold_scale (float): Scaling factor for Otsu's threshold. Default is 1.3.

    Returns:
        mask (ndarray): A binary mask where the largest contour is filled.
    '''
    def adjust_threshold(image, threshold_scale):
        '''
        Adjusts the threshold of the input image using Otsu's method and a scale factor.

        Parameters:
            image (ndarray): The input image to threshold.
            threshold_scale (float): The scaling factor for adjusting the Otsu threshold.

        Returns:
            binary_image (ndarray): The binary image after applying the threshold.
        '''
        # Compute Otsu threshold
        otsu_thresh = threshold_otsu(image)
        # Scale the threshold
        adjusted_thresh = otsu_thresh * threshold_scale
        # Create inverted binary image
        binary_image = image < adjusted_thresh  # Invert the binary mask
        return binary_image

    # Apply Gaussian blur to the image to reduce noise
    blurred_image = gaussian(image, sigma=2)
    # Adjust the threshold and create a binary image
    adjusted_binary = adjust_threshold(blurred_image, threshold_scale)
    # Remove small objects from the binary image
    adjusted_binary = remove_small_objects(adjusted_binary, min_size=1000)
    # Perform binary closing to fill small holes in the binary image
    adjusted_binary = binary_closing(adjusted_binary, selem=disk(5))
    # Convert the binary image to uint8 format for contour detection
    adjusted_binary_uint8 = (adjusted_binary * 255).astype(np.uint8)
    # Find contours in the binary image
    contours, _ = cv2.findContours(adjusted_binary_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # Initialize a mask with the same shape as the binary image
    mask = np.zeros_like(adjusted_binary_uint8)
    # If contours are found, draw the largest contour on the mask
    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        cv2.drawContours(mask, [largest_contour], 0, (255), thickness=cv2.FILLED)
        print(len(contours))
    return mask

def compute_centroid(binary_mask):
    '''
    Computes the centroid of the largest connected region in a binary mask.
    The centroid provides a stable, meaningful point for spatial analysis and image transformations.

    Parameters:
        binary_mask (ndarray): The binary mask where regions are labeled.

    Returns:
        (x, y) (tuple): The coordinates of the centroid of the largest region.
    '''
    # Label connected regions in the binary mask
    labeled_mask, num_labels = label(binary_mask, return_num=True)
    # Find the largest region by counting pixel occurrences
    largest_region = np.argmax(np.bincount(labeled_mask.flat)[1:]) + 1
    # Create a mask for the largest region
    largest_region_mask = labeled_mask == largest_region
    # Compute the centroid of the largest region
    centroid = center_of_mass(largest_region_mask)
    return int(centroid[1]), int(centroid[0])  # Return (x, y)

def apply_mask(original_image, binary_mask):
    '''
    Applies a binary mask to the input image, setting masked areas to black (0).
    This can effectively filtering out irrelevant parts, allowing for more focused feature extraction or image transformation.
    Parameters:
        original_image (ndarray): The original image.
        binary_mask (ndarray): The binary mask to apply.

    Returns:
        masked_image (ndarray): The image with the mask applied, where masked areas are set to black.
    '''
    # Use the binary mask to set corresponding areas in the original image to black
    masked_image = np.where(binary_mask, 0, original_image)  # Set mask area to 0 (black), keep other areas unchanged
    return masked_image

def plot_mask_with_centroid(image, mask, centroid, title, output_path):
    '''
    Plots an image with a colored mask overlay and marks the centroid point.
    By plotting both the mask and centroid, the user can visually verify whether the mask
    correctly covers the region of interest and whether the centroid is appropriately located.

    Parameters:
        image (ndarray): The original grayscale image.
        mask (ndarray): The binary mask where certain regions are highlighted.
        centroid (tuple): The (x, y) coordinates of the centroid to be marked.
        title (str): The title of the plot.
        output_path (str): The file path where the plot image will be saved.

    Returns:
        None: The function saves the plot to the specified output path and shows it.
    '''
    # Initialize an empty RGB mask, the same size as the input mask
    colored_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    # Set the mask areas where mask == 255 to red (BGR format)
    colored_mask[mask == 255] = [255, 0, 0]

    # Overlay the mask on the original image using transparency (0.7 original, 0.3 mask)
    overlay = cv2.addWeighted(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), 0.7, colored_mask, 0.3, 0)

    # Plot the image and mask with the centroid marked
    plt.figure(figsize=(10, 10))
    plt.imshow(overlay)
    plt.plot(centroid[0], centroid[1], 'ro')  # Mark the centroid with a red dot
    plt.title(title)
    # Save the plot to the specified output path
    plt.savefig(output_path)
    plt.show()

def find_min_grayvalue_point(image, x, y, box_size=10):
    '''
    Finds the coordinates of the minimum grayscale value in a box around the given point (x, y).
    This searches for the pixel with the lowest gray value within a small box around a specified (x, y) point.
    It helps identify the darkest (or least intense) point in the local area,
    which can be useful for locating key features or regions of interest in the image.

    Parameters:
        image (ndarray): The grayscale image to search within.
        x (int): The x-coordinate of the center point.
        y (int): The y-coordinate of the center point.
        box_size (int): The size of the box around the point (x, y) to search. Default is 10.

    Returns:
        (min_x, min_y) (tuple): The coordinates of the point with the minimum grayscale value in the box.
    '''
    # Define the boundaries of the box around the (x, y) point
    x_min = max(0, x - box_size // 2)
    x_max = min(image.shape[1], x + box_size // 2 + 1)
    y_min = max(0, y - box_size // 2)
    y_max = min(image.shape[0], y + box_size // 2 + 1)
    # Find the minimum value in the box area
    min_val = np.min(image[y_min:y_max, x_min:x_max])
    # Get the coordinates of the minimum value within the box
    min_loc = np.where(image[y_min:y_max, x_min:x_max] == min_val)
    min_x = x_min + min_loc[1][0]
    min_y = y_min + min_loc[0][0]
# Return the coordinates of the minimum grayscale value
    return (min_x, min_y)

def manual_select_sector_points(image, num_sectors=6):
    '''
    Allows the user to manually select sector points on an image by clicking, and stores the coordinates.
    By manually selecting points, users can ensure that the sectors align with important features in the image,
    improving the accuracy of subsequent analyses.

    Parameters:
        image (ndarray): The input image where the user will select points.
        num_sectors (int): The number of points/sectors to select. Default is 6.

    Returns:
        sector_points (list of tuples): A list of (x, y) coordinates of the selected points.
    '''
    # List to store selected points
    sector_points = []
    # Resize the image for better visibility during point selection
    image=resize_image(image, scale=0.5, width=None, height=None)
    def select_sector_point(event, x, y, flags, param):
        '''
        Callback function to handle mouse events. Adds points when the left mouse button is clicked.
        This function captures mouse clicks on an image, allowing users to select specific points that will define sectors or regions of interest.

        Parameters:
            event: The type of mouse event (e.g., left button down).
            x, y (int): Coordinates of the mouse event.
            flags: Optional flags parameter.
            param: Additional parameters.
        '''
       # If left mouse button is clicked
       if event == cv2.EVENT_LBUTTONDOWN:
            # Append the selected point to the sector_points list
            sector_points.append((x, y))
            # Draw a red circle at the selected point
            cv2.circle(image, (x, y), 5, (0, 0, 255), -1)
            cv2.imshow('Select Sector Points', image)
            # If the desired number of points is reached, close the window
            if len(sector_points) == num_sectors:
                cv2.destroyWindow('Select Sector Points')
    # Display the image and set the mouse callback for point selection
    cv2.imshow('Select Sector Points', image)
    cv2.setMouseCallback('Select Sector Points', select_sector_point)
    # Wait for the user to finish selecting points
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    # Return the list of selected points
    return sector_points

def get_sector(x, y, center, sector_points):
    '''
    Determines the sector closest to a given (x, y) point based on the provided sector points.
    This function helps identify the specific sector that a point belongs to in a defined polar coordinate system, based on its angular position relative to a center point.

    Parameters:
        x, y (int): The coordinates of the point to evaluate.
        center (tuple): The (x, y) coordinates of the center, though it's unused here.
        sector_points (list of tuples): A list of (x, y) coordinates representing the sector points.

    Returns:
        sector (int): The index (starting from 1) of the closest sector point.
    '''
    # Initialize minimum distance to infinity
    min_dist = float('inf')
    sector = 0
    # Iterate over each sector point and compute the Euclidean distance
    for i, (sx, sy) in enumerate(sector_points):
        # Compute the distance from the (x, y) point to each sector point
        dist = np.hypot(sx - x, sy - y)
        # Update the closest sector if a shorter distance is found
        if dist < min_dist:
            min_dist = dist
            # Sector indices start at 1
            sector = i + 1
    # Return the closest sector
    return sector

def manual_select_keypoints(images, center, sector_points, titles=["Reference Image", "Moving Image"],scale=0.5):
    '''
    Allows the user to manually select keypoints on two images, store those keypoints, and associate each with a sector.
    This function enables users to manually select keypoints in two images (often a reference and a moving image) based on visual inspection,
    aiding in image registration or feature tracking tasks.

    Parameters:
        images (list of ndarray): A list of two images for keypoint selection.
        center (tuple): The center (x, y) of the image, used for sector identification.
        sector_points (list of tuples): Predefined points dividing the image into sectors.
        titles (list of str): The titles of the windows showing the two images. Default is ["Reference Image", "Moving Image"].
        scale (float): Scaling factor for resizing the images during selection. Default is 0.5.

    Returns:
        keypoints (list of list of tuples): A list containing two lists of selected keypoints for each image.
        sectors (list of list of int): A list containing two lists of sector indices for the keypoints in each image.
    '''
    # Initialize lists to store keypoints and sectors for both images
    keypoints = [[], []]
    sectors = [[], []]
    # Keeps track of the selected point in both images
    selected_point = [-1, -1]
    # Resize images for better visualization during keypoint selection
    images = [resize_image(image, scale) for image in images]

    def select_point(event, x, y, flags, param):
        '''
        Callback function for handling mouse events during point selection.

        Parameters:
            event: The type of mouse event (e.g., left or right button click).
            x, y (int): The coordinates of the mouse event.
            flags: Optional flags parameter.
            param: Dictionary containing the index of the image being selected (0 or 1).
        '''
        # Identify which image is being worked on (0 = Reference Image, 1 = Moving Image)
        img_index = param["img_index"]
        # Left mouse button click event
        if event == cv2.EVENT_LBUTTONDOWN:
            # Find the point with the minimum gray value in the vicinity of the clicked point
            min_point = find_min_grayvalue_point(images[img_index], x, y)
            # Append the selected keypoint to the keypoints list for the current image
            keypoints[img_index].append(min_point)
            # Determine the sector of the selected point based on its distance to sector points
            sector = get_sector(min_point[0], min_point[1], center, sector_points)
            # Append the sector to the sectors list for the current image
            sectors[img_index].append(sector)
            # Draw a green circle and label at the selected point to mark it visually
            cv2.circle(images[img_index], min_point, 5, (0, 255, 0), -1)
            cv2.putText(images[img_index], f"{len(keypoints[img_index])}(Sec{sector})", min_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            # Update the displayed image with the marked point
            cv2.imshow(titles[img_index], images[img_index])
            # Update the selected point for the first image and draw a corresponding rectangle on the second image
            if img_index == 0:
                selected_point[0] = min_point
                draw_rectangle_on_other_image(*min_point)
            # Update the selected point for the second image and clear any rectangle from the first image
            elif img_index == 1:
                selected_point[1] = min_point
                clear_rectangle_on_other_image()
        # Right mouse button click event
        elif event == cv2.EVENT_RBUTTONDOWN:
            # Iterate through existing keypoints in the current image to find one close to the clicked point
            for i, (px, py) in enumerate(keypoints[img_index]):
                # If the clicked point is within a 10-pixel radius of a keypoint, remove it
                if (px - 10 <= x <= px + 10) and (py - 10 <= y <= py + 10):
                    keypoints[img_index].pop(i)
                    sectors[img_index].pop(i)
                    # If there's a corresponding keypoint in the other image, remove it too
                    if len(keypoints[1 - img_index]) > i:
                        keypoints[1 - img_index].pop(i)
                        sectors[1 - img_index].pop(i)
                    # Redraw both images to reflect the removal of the keypoints
                    redraw_images()
                    return

    def draw_rectangle_on_other_image(x, y):
        '''
        Draws a rectangle on the second image (index 1) at the position corresponding to the selected point in the first image (index 0).

        Parameters:
        x, y (int): The coordinates of the selected point in the first image.
        '''
        # Define the rectangle's boundaries, ensuring they don't exceed image dimensions
        x_min = max(0, x - 10)
        x_max = min(images[1].shape[1], x + 10)
        y_min = max(0, y - 10)
        y_max = min(images[1].shape[0], y + 10)
        # Draw a blue rectangle around the specified point on the second image
        cv2.rectangle(images[1], (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)
        # Display the updated second image with the rectangle
        cv2.imshow(titles[1], images[1])

    def clear_rectangle_on_other_image():
        '''
        Clears any drawn rectangle by redrawing both images with all current keypoints, effectively removing the rectangle.
        '''
        # Redraw both images to clear visual changes such as the rectangle
        redraw_images()

    def redraw_images():
        '''
        Redraws both images, showing the current keypoints and their corresponding sectors.
        This is used to refresh the images after changes, such as point selection or deletion.

        Functionality:
        - Reloads the images and resizes them.
        - Converts them from grayscale to BGR for color drawing.
        - Redraws each keypoint and labels them with their sector number.
         '''
        for img_index in range(2):
            # Reload and resize the image
            images[img_index] = resize_image(cv2.imread(image_paths[img_index], cv2.IMREAD_GRAYSCALE),scale)
            # Convert the grayscale image to BGR (color) so we can draw colored points
            images[img_index] = cv2.cvtColor(images[img_index], cv2.COLOR_GRAY2BGR)
            # Redraw each keypoint on the image, labeling it with its corresponding sector number
            for i, (x, y) in enumerate(keypoints[img_index]):
                sector = sectors[img_index][i]
                # Draw a green circle for each keypoint
                cv2.circle(images[img_index], (x, y), 5, (0, 255, 0), -1)
                # Add a text label showing the point index and sector number
                cv2.putText(images[img_index], f"{i + 1}(Sec{sector})", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                # Display the updated image
                cv2.imshow(titles[img_index], images[img_index])

    # Main loop to set up the image windows and mouse callbacks
    for i, img in enumerate(images):
        # Show the image in a window with the corresponding title
        cv2.imshow(titles[i], img)
        # Set a mouse callback for selecting points
        cv2.setMouseCallback(titles[i], select_point, param={"img_index": i})

    # Wait until the user presses a key to close the windows
    cv2.waitKey(0)
    # Close all OpenCV windowscv2.destroyAllWindows()
    cv2.destroyAllWindows()
    # Return the selected keypoints and sectors for both images
    return keypoints[0], keypoints[1], sectors[0], sectors[1]

def calculate_sector_radii(mask, centroid, sector_points, num_points=30):
    '''
    Calculates the average radial distances from the centroid to the mask boundary for each sector.

    Parameters:
        mask (np.array): The binary mask where the shape is defined.
        centroid (tuple): The (x, y) coordinates of the shape's centroid.
        sector_points (list of tuples): List of points defining the sector boundaries.
        num_points (int): Number of points sampled along each sector boundary for distance calculation.

    Returns:
        sector_radii (list): A list of average radial distances for each sector.
    '''
    # To store the average radius for each sector
    sector_radii = []
    # Number of sectors based on the number of points
    num_sectors = len(sector_points)

    for i in range(num_sectors):
        # Get the coordinates of the current sector point and the next one (wrapping around)
        sx1, sy1 = sector_points[i]
        # Circular connection to form a loop
        sx2, sy2 = sector_points[(i + 1) % num_sectors]  # 下一个扇区点，形成一个环
        # Calculate the distance between the two sector points in the x and y directions
        dist_x = sx2 - sx1
        dist_y = sy2 - sy1
        # Store distances from centroid to boundary along the sector line
        distances = []
        # Iterate through points between the two sector boundary points
        for j in range(num_points + 1):
            # Linear interpolation factor
            t = j / num_points
            # Interpolated x-coordinate along the boundary
            x = int(sx1 + t * dist_x)
            # Interpolated y-coordinate along the boundary
            y = int(sy1 + t * dist_y)
            # Ensure the point is on the mask boundary
            if mask[y, x] != 0:
                # Distance from centroid
                dist = np.sqrt((x - centroid[0])**2 + (y - centroid[1])**2)
                # Collect the distance if the point is valid
                distances.append(dist)
        # Calculate the average distance for this sector
        if distances:
            # If distances are found, take the mean
            avg_distance = np.mean(distances)
        else:
            # If no valid points were found, set average distance to 0
            avg_distance = 0
        # Store the average distance for the sector
        sector_radii.append(avg_distance)
    # Optionally print the calculated sector radii
    print(sector_radii)
    # Return the list of average distances for each sector
    return sector_radii

def compute_distances(keypoints1, keypoints2, sectors1, sectors2, sector_radii, center):
    '''
    Computes the normalized distances and radial displacements between two sets of keypoints.

    Parameters:
        keypoints1 (list of tuples): Key points from the first image (reference image).
        keypoints2 (list of tuples): Key points from the second image (moving image).
        sectors1 (list): Sector assignments for each keypoint in the first image.
        sectors2 (list): Sector assignments for each keypoint in the second image.
        sector_radii (list): List of average radii for each sector.
        center (tuple): The (x, y) coordinates of the centroid.

    Returns:
        normalized_distances (list): List of normalized distances between keypoints.
        radial_disp (list): List of radial displacements between the two keypoint sets.
    '''
    # To store Euclidean distances between corresponding keypoints
    distances = []
    # To store normalized distances (distance / sector radius)
    normalized_distances = []
    # To store the radial displacement between corresponding keypoints
    radial_disp = []

    # Iterate through each pair of keypoints and their respective sectors
    for (x1, y1), (x2, y2), sector1, sector2 in zip(keypoints1, keypoints2, sectors1, sectors2):
        # Scale the keypoint coordinates by 2 (undo any prior resizing or normalization)
        x1=x1*2
        x2=x2*2
        y1=y1*2
        y2=y2*2
        # Calculate the Euclidean distance of the first keypoint from the centroid
        dist = np.sqrt((x1 - center[0])**2 + (y1 - center[1])**2)
        distances.append(dist)

        # Calculate the angles (theta) of both keypoints relative to the centroid
        theta1 = np.arctan2(y1 - center[1], x1 - center[0])
        theta2 = np.arctan2(y2 - center[1], x2 - center[0])

        # Compute the radial distances of both keypoints from the centroid
        ref_radial_dist = np.sqrt((x1 - center[0])**2 + (y1 - center[1])**2)
        mov_radial_dist = np.sqrt((x2 - center[0])**2 + (y2 - center[1])**2)

        # Calculate the radial displacement between the two keypoints based on their angles
        radial_displacement = mov_radial_dist  * np.cos(theta2 - theta1)- ref_radial_dist
        radial_disp.append(radial_displacement)

        # Normalize the distance using the radius of sector1
        # Sectors are 1-indexed, so subtract 1 for array indexing
        sector_radius = sector_radii[sector1 - 1]
        # Avoid division by zero
        normalized_distance = dist / sector_radius if sector_radius != 0 else 0
        normalized_distances.append(normalized_distance)

    return normalized_distances, radial_disp

def save_to_excel(keypoints1, keypoints2, sectors1, sectors2,  normalized_distances, displacements, output_path):
    '''
    Saves the keypoints, sector information, and computed distances to an Excel file.

    Parameters:
        keypoints1 (list of tuples): Key points from the first (reference) image.
        keypoints2 (list of tuples): Key points from the second (moving) image.
        sectors1 (list): Sector assignments for the keypoints in the first image.
        sectors2 (list): Sector assignments for the keypoints in the second image.
        normalized_distances (list): List of normalized distances between keypoints.
        displacements (list): List of radial displacements for each keypoint pair.
        output_path (str): File path where the Excel file will be saved.

    Returns:
        None. Saves the data to an Excel file.
    '''
    data = []
    # Loop through each keypoint pair and their associated sector and distance data
    for i, ((x1, y1), (x2, y2), sector1, sector2, norm_dist, disp) in enumerate(zip(keypoints1, keypoints2, sectors1, sectors2,normalized_distances, displacements)):
        # Prepare the data dictionary for each keypoint pair
        data.append({
            "Match Index": i + 1,  # Keypoint pair index, starting from 1
            "x1": x1 * 2,  # Scale the x1 coordinate from keypoints1 (to undo any resizing)
            "y1": y1 * 2,  # Scale the y1 coordinate from keypoints1
            "Reference Sector": sector1,  # Sector number in reference image
            "x2": x2 * 2,  # Scale the x2 coordinate from keypoints2
            "y2": y2 * 2,  # Scale the y2 coordinate from keypoints2
            "Moving Sector": sector2,  # Sector number in moving image
            "Distance": norm_dist,  # Normalized distance between keypoints
            "Disp": disp  # Radial displacement between keypoints
        })

    # Create a Pandas DataFrame to store all the data
    df = pd.DataFrame(data)
    # Save the DataFrame to an Excel file at the specified output path
    df.to_excel(output_path, index=False)

def find_closest_contour_point(contour, point):

    '''
    Finds the point on a given contour that is closest to a specified point.

    Parameters:
        contour (ndarray): The contour points of the tumor.
        point (tuple): The manually selected point (x, y).

    Returns:
        closest_point (tuple): The point on the contour that is closest to the specified point.
    '''
    # Initialize minimum distance as infinity
    min_dist = float('inf')
    # Initialize closest point
    closest_point = None
    # Iterate through each point in the contour
    for contour_point in contour:
        # Calculate the Euclidean distance between the current contour point and the specified point
        dist = np.linalg.norm(np.array(contour_point[0]) - np.array(point))
        # If the current distance is smaller than the previous minimum, update the closest point
        if dist < min_dist:
            min_dist = dist
            closest_point = contour_point[0]
    # Return the closest point as a tuple
    return tuple(closest_point)

def update_sector_points_with_contour(sector_points, contour):
    '''
    Updates the manually selected sector points by finding their closest points on the tumor contour.

    Parameters:
        sector_points (list of tuples): List of manually selected sector points (x, y).
        contour (ndarray): Contour points of the tumor.

    Returns:
        updated_points (list of tuples): List of updated sector boundary points based on the closest contour points.
    '''

    updated_points = []
    # Loop through each manually selected sector point
    for point in sector_points:
        # Find the closest point on the contour to the current sector point
        closest_contour_point = find_closest_contour_point(contour, point)
        # Append the closest contour point to the list of updated points
        updated_points.append(closest_contour_point)
    # Return the updated sector points
    return updated_points

def main(image_paths, outd):
    '''
    Main function to process images, select keypoints, compute distances,
    and save the results to an Excel file and images with keypoints.
    '''
    output_dir = outd
    # Create output directory if it does not exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    # Load images from the provided paths
    images = load_images(image_paths)
    reference_image = cv2.convertScaleAbs(images[0])
    moving_image = cv2.convertScaleAbs(images[1])
    # Apply Gaussian blur to both images
    blurred_reference = gaussian(reference_image, sigma=2)
    blurred_moving = gaussian(moving_image, sigma=2)
    # Increase threshold by 30%
    threshold_scale = 1.3
    # Adjust threshold and clean up the binary images
    adjusted_binary_ref = adjust_threshold(blurred_reference, threshold_scale)
    adjusted_binary_ref = remove_small_objects(adjusted_binary_ref, min_size=1000)
    adjusted_binary_ref = binary_closing(adjusted_binary_ref, selem=disk(5))
    adjusted_binary_mov = adjust_threshold(blurred_moving, threshold_scale)
    adjusted_binary_mov = remove_small_objects(adjusted_binary_mov, min_size=1000)
    adjusted_binary_mov = binary_closing(adjusted_binary_mov, selem=(disk(5)))
    # Apply masks to the original images
    masked_reference_image = apply_mask(reference_image, adjusted_binary_ref.copy())
    masked_moving_image = apply_mask(moving_image, adjusted_binary_mov.copy())
    # Enhance contrast of the masked images
    enhanced_reference_image = enhance_contrast(masked_reference_image)
    enhanced_moving_image = enhance_contrast(masked_moving_image)
    # Prepare images for manual selection of sector points
    ref_image_for_selection = cv2.cvtColor(reference_image, cv2.COLOR_GRAY2BGR)
    mov_image_for_selection = cv2.cvtColor(moving_image, cv2.COLOR_GRAY2BGR)
    # Create tumor shape masks and compute centroids
    circle_mask, masked_reference_image_circle = create_circle_mask(reference_image)
    circle_mask, masked_moving_image_circle = create_circle_mask(moving_image)
    largest_contour_mask_ref = create_largest_contour_mask(masked_reference_image_circle)
    largest_contour_mask_mov = create_largest_contour_mask(masked_moving_image_circle)
    center_ref = compute_centroid(largest_contour_mask_ref)
    center_mov = compute_centroid(largest_contour_mask_mov)
    # Print centroids' coordinates
    print(f"Reference Image Centroid: {center_ref}")
    print(f"Moving Image Centroid: {center_mov}")
    # Plot masks and centroids
    plot_mask_with_centroid(reference_image, largest_contour_mask_ref, center_ref, 'Reference Image Mask and Centroid', os.path.join(output_dir, 'reference_image_mask_centroid.png'))
    plot_mask_with_centroid(moving_image, largest_contour_mask_mov, center_mov, 'Moving Image Mask and Centroid', os.path.join(output_dir, 'moving_image_mask_centroid.png'))
    # Manually select sector points on the reference image
    sector_points = manual_select_sector_points(ref_image_for_selection.copy(), num_sectors=6)
    # Extract tumor contours from the largest contour mask
    contours_ref, _ = cv2.findContours(largest_contour_mask_ref, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # Use the largest contour
    tumor_contour_ref = contours_ref[0]
    # Update sector points based on the contour
    updated_sector_points = update_sector_points_with_contour(sector_points, tumor_contour_ref)
    # Calculate radii for each sector
    sector_radii = calculate_sector_radii(largest_contour_mask_ref, center_ref, updated_sector_points, num_points=30)
    print("Sector Radii:", sector_radii)

    """use the second part of code to get the points"""
    # Select keypoints on the reference and moving images
    images=[imageio.imread(path) for path in image_paths]
    print("Select keypoints on the reference and moving images")
    keypoints_ref, keypoints_mov, sectors_ref, sectors_mov = manual_select_keypoints(
        [images[0], images[1]], center_ref, sector_points, titles=["Reference Image", "Moving Image"],scale=0.5)
    # Ensure the same number of keypoints are selected on both images
    if len(keypoints_ref) != len(keypoints_mov):
        print("Error: The number of keypoints selected on both images must be the same.")
        return
    # Compute normalized distances and displacements
    normalized_distances, displacements = compute_distances(keypoints_ref, keypoints_mov, sectors_ref, sectors_mov, sector_radii, center_ref)
    # Save matched points and distances to an Excel file
    excel_output_path = os.path.join(output_dir, 'matched_points_and_distances_manual.xlsx')
    save_to_excel(keypoints_ref, keypoints_mov, sectors_ref, sectors_mov, normalized_distances, displacements, excel_output_path)
    print(f"Matched points and distances saved to {excel_output_path}")
    # Draw keypoints on the selected images
    for (x1, y1), (x2, y2), sector1, sector2 in zip(keypoints_ref, keypoints_mov, sectors_ref, sectors_mov):
        cv2.circle(ref_image_for_selection, (x1*2, y1*2), 5, (0, 255, 0), -1)
        cv2.putText(ref_image_for_selection, f"(Sec{sector1})", (x1*2, y1*2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        cv2.circle(mov_image_for_selection, (x2*2, y2*2), 5, (0, 255, 0), -1)
        cv2.putText(mov_image_for_selection, f"(Sec{sector2})", (x2*2, y2*2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    # Save images with keypoints
    imageio.imwrite(os.path.join(output_dir, 'reference_image_with_manual_kp.tif'), ref_image_for_selection)
    imageio.imwrite(os.path.join(output_dir, 'moving_image_with_manual_kp.tif'), mov_image_for_selection)

    print("Images with manually selected keypoints saved.")
    # Display images with keypoints
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].imshow(cv2.cvtColor(ref_image_for_selection, cv2.COLOR_BGR2RGB))
    axs[0].set_title('Reference Image with Keypoints')
    axs[1].imshow(cv2.cvtColor(mov_image_for_selection, cv2.COLOR_BGR2RGB))
    axs[1].set_title('Moving Image with Keypoints')
    plt.show()

if __name__ == "__main__":
    """
    Entry point of the script. Define image paths and output directory,
    then call the main function.
    """
    image_paths = [
        'C:\\Users\\austa\\Downloads\\eighth_0.4\\Day 0 + 88bit.tif',
        'C:\\Users\\austa\\Downloads\\eighth_0.4\\Day 4 + 88bit.tif'
    ]
    outd = 'C:\\Users\\austa\\Downloads\\output'
    main(image_paths, outd)