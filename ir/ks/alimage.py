# -*- coding: utf-8 -*-
"""alimage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NfBAx1wukMdws-an1LX_UiwCWtpQc2tq

## Alimage READ ME
Date Version : 10/01/2024

The Alimage script is designed for image alignment and processing, utilizing ORB (Oriented FAST and Rotated BRIEF) feature matching. It loads two input images, enhances their contrast through CLAHE (Contrast Limited Adaptive Histogram Equalization), and applies a mask to exclude the central region for feature detection. By matching keypoints between the two images, it calculates an affine transformation matrix to align the moving image with the reference. The aligned and reference images are then cropped to a specified region and saved in an output directory. The aligned and cropped images are also displayed using Matplotlib. This tool is ideal for image registration and region-based cropping applications.

Oriented FAST: This variant of the FAST algorithm enhances its performance by incorporating orientation information, allowing it to detect keypoints that are invariant to rotation.

Rotated BRIEF: This technique extends the BRIEF descriptor to handle rotations of the image, ensuring that the keypoint descriptors remain consistent even if the image is rotated.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import imageio
import os

def load_images(paths):
'''
    Load images from the provided file paths.

    Parameters:
    paths: list of strings
        A list of file paths to the images that need to be loaded.

    Returns:
    images: list of arrays
        A list of loaded images in array format.
    '''
    images = [imageio.imread(path) for path in paths]
    return images

def enhance_contrast(image):
'''
    Enhance the contrast of a grayscale image using CLAHE (Contrast Limited Adaptive Histogram Equalization).
    Enhancing contrast works by adjusting the grayscale values of an image,
    increasing the difference between light and dark areas.
    This process makes details more visible by stretching or redistributing the pixel intensities.
    For example, in medical images, enhancing contrast helps distinguish subtle differences between tissues,
    making structures like tumors stand out more clearly for further analysis.
    Parameters:
    image: 2D numpy array
        The input grayscale image to enhance the contrast of.

    Returns:
    enhanced_image: 2D numpy array
        The contrast-enhanced image.
    '''
    # Create CLAHE object with specified clip limit and tile grid size
    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
    # Apply CLAHE to enhance the contrast of the image
    enhanced_image = clahe.apply(image)
    return enhanced_image

def mask_center(image, mask_size):
'''
    Apply a central mask to an image. The mask blocks out a square area in the center of the image.
    Apply mask at center to exclude the image's central region from feature detection and processing.
    This is useful when the center contains irrelevant or distracting information,
    such as noise or a static object that doesn't contribute to the alignment or analysis.

    Parameters:
    image: 2D numpy array
        The input grayscale image to apply the mask to.
    mask_size: int
        The size of the square mask to apply in the center of the image.

    Returns:
    masked_image: 2D numpy array
        The image with the center masked out.
    '''
    # Get image dimensions
    h, w = image.shape
    # Calculate the coordinates of the center of the image
    center_x, center_y = w // 2, h // 2
    # Calculate half of the mask size to create the square in the center
    half_mask_size = mask_size // 2
    # Initialize a white mask (255 for visible areas)
    mask = np.ones((h, w), dtype=np.uint8) * 255
    # Create a black square at the center of the mask
    mask[center_y - half_mask_size:center_y + half_mask_size, center_x - half_mask_size:center_x + half_mask_size] = 0
    # Apply mask to the image using bitwise AND
    return cv2.bitwise_and(image, mask)

def align_images_orb(reference_image, moving_image, mask_size):
'''
    Align two images using ORB (Oriented FAST and Rotated BRIEF) feature detection and matching.
    This detects and matches keypoints between the two images,
    computes an affine transformation matrix,
    and applies this transformation to align the moving image with the reference.
    This process is essential for image registration tasks,
    ensuring that corresponding features in both images are properly aligned for accurate comparison or analysis.

    Oriented FAST: This variant of the FAST algorithm enhances its performance by incorporating orientation information,
    allowing it to detect keypoints that are invariant to rotation.
    Rotated BRIEF: This technique extends the BRIEF descriptor to handle rotations of the image,
    ensuring that the keypoint descriptors remain consistent even if the image is rotated.


    Parameters:
    reference_image: 2D numpy array
        The reference image that the moving image will be aligned to.
    moving_image: 2D numpy array
        The moving image that needs to be aligned to the reference image.
    mask_size: int
        The size of the square mask applied to the center of both images to ignore that region.

    Returns:
    aligned_image: 2D numpy array
        The aligned version of the moving image.
    reference_image: 2D numpy array
        The reference image (not modified but returned for completeness).
    '''
    # Create ORB feature detector
    orb = cv2.ORB_create()
    # Enhance contrast
    reference_image_enhanced = enhance_contrast(reference_image)
    moving_image_enhanced = enhance_contrast(moving_image)
    # Apply mask to the images
    reference_image_masked = mask_center(reference_image_enhanced, mask_size)
    moving_image_masked = mask_center(moving_image_enhanced, mask_size)
    # Detect keypoints and compute descriptors
    keypoints1, descriptors1 = orb.detectAndCompute(reference_image_masked, None)
    keypoints2, descriptors2 = orb.detectAndCompute(moving_image_masked, None)
    # Create BFMatcher for descriptor matching
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(descriptors1, descriptors2)
    # Sort matches by distance
    matches = sorted(matches, key=lambda x: x.distance)
    # Extract matched point positions
    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 2)
    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 2)
    # Compute affine transform matrix
    M, mask = cv2.estimateAffinePartial2D(dst_pts, src_pts)
    # Apply affine transform to align images
    aligned_image = cv2.warpAffine(moving_image, M, (reference_image.shape[1], reference_image.shape[0]))

    return aligned_image, reference_image

def crop_image(image, x_start, x_end, y_start, y_end):
  '''
     Crop the image to the specified rectangular region
     Cropping to focus on a particular area of interest within an image, can help reduce processing time and enhance the analysis of relevant features.

     Parameters:
    image: 2D numpy array
        The input image that needs to be cropped.
    x_start: int
        The starting x-coordinate of the crop (left boundary).
    x_end: int
        The ending x-coordinate of the crop (right boundary).
    y_start: int
        The starting y-coordinate of the crop (top boundary).
    y_end: int
        The ending y-coordinate of the crop (bottom boundary).

    Returns:
    cropped_image: 2D numpy array
        The cropped image.
    '''
    return image[y_start:y_end, x_start:x_end]

def main(image_paths,output_dir):
  '''
    Main function to load, process, align, and save images.

    Parameters:
    image_paths: list of strings
        List of file paths for the images to be processed.
    output_dir: string
        Directory where the output images will be saved. (Both aligned_image_cropped & reference_image_cropped)

    Returns:
    aligned_image_cropped: 2D numpy array
        The cropped and aligned moving image.
    reference_image_cropped: 2D numpy array
        The cropped reference image.
    '''
    output_dir = output_dir
    # Create output directory if it doesn't exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    # Load the images from the provided paths
    images = load_images(image_paths)
    # Convert loaded images to 8-bit for further processing
    reference_image = cv2.convertScaleAbs(images[0])
    moving_image = cv2.convertScaleAbs(images[1])
    # Define mask size
    mask_size = 1000
    # Align images
    aligned_image, reference_image_masked = align_images_orb(reference_image, moving_image, mask_size)
    # Crop images to specified dimensions
    x_start, x_end = 10, 2400
    y_start, y_end = 10, 2000
    # Crop both the aligned and reference images to the specified region
    reference_image_cropped = crop_image(reference_image, x_start, x_end, y_start, y_end)
    aligned_image_cropped = crop_image(aligned_image, x_start, x_end, y_start, y_end)

    # Save images
    imageio.imwrite(os.path.join(output_dir, 'aligned_image_cropped.tif'), aligned_image_cropped)
    imageio.imwrite(os.path.join(output_dir, 'reference_image_cropped.tif'), reference_image_cropped)

    print("Aligned and cropped image saved.")
    print("Cropped reference image saved.")

    # Display aligned and cropped image and masked reference image
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].imshow(reference_image_cropped, cmap='gray')
    axs[0].set_title('Cropped Reference Image')
    axs[1].imshow(aligned_image_cropped, cmap='gray')
    axs[1].set_title('Aligned and Cropped Image')
    plt.show()

    return aligned_image_cropped,reference_image_cropped
if __name__ == "__main__":
    # File paths for images to align
    image_paths = [
        'C:\\Users\\austa\\Downloads\\eighth_0.4\\Day 0 + 88bit.tif',
        'C:\\Users\\austa\\Downloads\\eighth_0.4\\Day 4 + 88bit.tif'
    ]
    # Specify output directory for saved images
    main(image_paths)
    # Define the output directory for saving the results